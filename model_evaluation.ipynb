{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a640f87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 File Created\n",
    "import pandas as pd \n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28d38f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 evaluate by hand the  model performance\n",
    "# acc: .80\n",
    "# 46/53 .87\n",
    "# 46/59 .78\n",
    "# A false positive is Predicted == X, but actual != x\n",
    "# A false negative is Predicted != X, but actual == x\n",
    "# This model is fairly acurrate compared to guessing, but performance would need to \n",
    "# drastically improve for production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1c17580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 C3 datascientist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e1000fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>model1</th>\n",
       "      <th>model2</th>\n",
       "      <th>model3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      actual     model1  model2     model3\n",
       "0  No Defect  No Defect  Defect  No Defect\n",
       "1  No Defect  No Defect  Defect     Defect\n",
       "2  No Defect  No Defect  Defect  No Defect\n",
       "3  No Defect     Defect  Defect     Defect\n",
       "4  No Defect  No Defect  Defect  No Defect"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read-in the dataset\n",
    "df = pd.read_csv('c3.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82bf67e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>model3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      actual     model3\n",
       "0  No Defect  No Defect\n",
       "1  No Defect     Defect\n",
       "2  No Defect  No Defect\n",
       "3  No Defect     Defect\n",
       "4  No Defect  No Defect"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FIRST WE SPLIT UP THE dfs into 3 seperate DFs, one for each model:\n",
    "df1 = df.drop(columns=['model2','model3'])\n",
    "df1.head()\n",
    "df2 = df.drop(columns=['model1','model3'])\n",
    "df2.head()\n",
    "df3 = df.drop(columns=['model1','model2'])\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6744673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>actual</th>\n",
       "      <th>Defect</th>\n",
       "      <th>No Defect</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Defect</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No Defect</th>\n",
       "      <td>8</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "actual     Defect  No Defect\n",
       "model1                      \n",
       "Defect          8          2\n",
       "No Defect       8        182"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ACTUALLY, lets answer the questions that can be answered at this point:\n",
    "# Which METRIC is useful to ID all DEFECTS:  RECALL TP/(TP+FN)  TP/ALL ACTUAL\n",
    "# Now, which model 1,2,3 has highest RECALL VALUE?\n",
    "pd.crosstab(df.model1,df.actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c333810a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_acc = (df1.model1 == df1.actual).mean()\n",
    "model1_acc\n",
    "\n",
    "subset = df1[df1.actual == 'Defect']\n",
    "subset.shape\n",
    "model1_recall = (subset.model1 == subset.actual).mean()\n",
    "model1_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d51590e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>actual</th>\n",
       "      <th>Defect</th>\n",
       "      <th>No Defect</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Defect</th>\n",
       "      <td>9</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No Defect</th>\n",
       "      <td>7</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "actual     Defect  No Defect\n",
       "model2                      \n",
       "Defect          9         81\n",
       "No Defect       7        103"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(df.model2,df.actual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d28a57ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5625"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_acc = (df2.model2 == df2.actual).mean()\n",
    "model2_acc\n",
    "subset = df2[df2.actual == 'Defect']\n",
    "subset.shape\n",
    "\n",
    "model2_recall = (subset.model2 == subset.actual).mean()\n",
    "model2_recall  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b008901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>actual</th>\n",
       "      <th>Defect</th>\n",
       "      <th>No Defect</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model3</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Defect</th>\n",
       "      <td>13</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No Defect</th>\n",
       "      <td>3</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "actual     Defect  No Defect\n",
       "model3                      \n",
       "Defect         13         86\n",
       "No Defect       3         98"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(df.model3,df.actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5092a9a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8125"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3_acc = (df3.model3 == df3.actual).mean()\n",
    "model3_acc\n",
    "subset = df3[df3.actual == 'Defect']\n",
    "subset.shape\n",
    "\n",
    "model3_recall = (subset.model3 == subset.actual).mean()\n",
    "model3_recall \n",
    "# Model 3 has greatest RECALL at 0.8125...(13/16), but we really need to get a better model..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596599bd",
   "metadata": {},
   "source": [
    "- and the winner is ... MODEL 3 with Recall = .8125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "844816c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VACA to Hawaii \n",
    "# The best METRIC to evaluate on to prevent a trip to HAWAII (A FALSE NEGATIVE) is RECALL...\n",
    "# THe relative cost of removing a Type I False Positive is low compared to giving away a trip to Hawaii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7c785c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOW, which model has the Highest RECALL...\n",
    "# RESTRICT EVAL to ONLY ACTUAL POS!\n",
    "\n",
    "subset = df1[df1.actual == 'Defect']\n",
    "subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "016492b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_recall = (subset.model1 == subset.actual).mean()\n",
    "model1_recall  # Ugh....recall of .50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd3d1608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5625"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = df2[df2.actual == 'Defect']\n",
    "subset.shape\n",
    "\n",
    "model2_recall = (subset.model2 == subset.actual).mean()\n",
    "model2_recall  # Ugh recall of .56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8562fa8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8125"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = df3[df3.actual == 'Defect']\n",
    "subset.shape\n",
    "\n",
    "model3_recall = (subset.model3 == subset.actual).mean()\n",
    "model3_recall  # right now, this is best with .8125\n",
    "\n",
    "\n",
    "# Model 3 has greatest RECALL at 0.8125...(3/16), but we really need to get a better model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9465a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   actual  5000 non-null   object\n",
      " 1   model1  5000 non-null   object\n",
      " 2   model2  5000 non-null   object\n",
      " 3   model3  5000 non-null   object\n",
      " 4   model4  5000 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 195.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# 4 GIVES_YOU_PAWS dataset...\n",
    "# first, create a baseline model\n",
    "df = pd.read_csv('gives_you_paws.csv')\n",
    "df.head()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63ac0e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>model4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  actual model4\n",
       "0    cat    dog\n",
       "1    dog    dog\n",
       "2    dog    dog\n",
       "3    dog    dog\n",
       "4    cat    dog"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FIRST WE SPLIT UP THE dfs into 4 seperate DFs, one for each model:\n",
    "df1 = df.drop(columns=['model2','model3','model4'])\n",
    "df1.head()\n",
    "df2 = df.drop(columns=['model1','model3','model4'])\n",
    "df2.head()\n",
    "df3 = df.drop(columns=['model1','model2','model4'])\n",
    "df3.head()\n",
    "df4 = df.drop(columns=['model1','model2','model3'])\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d33716c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>actual</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>1423</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>323</td>\n",
       "      <td>2614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "actual   cat   dog\n",
       "model1            \n",
       "cat     1423   640\n",
       "dog      323  2614"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(df.model1,df.actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "507f0559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>actual</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>1555</td>\n",
       "      <td>1657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>191</td>\n",
       "      <td>1597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "actual   cat   dog\n",
       "model2            \n",
       "cat     1555  1657\n",
       "dog      191  1597"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(df.model2,df.actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23826a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>actual</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model3</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>893</td>\n",
       "      <td>1599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>853</td>\n",
       "      <td>1655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "actual  cat   dog\n",
       "model3           \n",
       "cat     893  1599\n",
       "dog     853  1655"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(df.model3,df.actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40de8a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>actual</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model4</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>603</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>1143</td>\n",
       "      <td>3110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "actual   cat   dog\n",
       "model4            \n",
       "cat      603   144\n",
       "dog     1143  3110"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(df.model4,df.actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7a42935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a27b8eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>model1</th>\n",
       "      <th>model2</th>\n",
       "      <th>model3</th>\n",
       "      <th>model4</th>\n",
       "      <th>baseline_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  actual model1 model2 model3 model4 baseline_prediction\n",
       "0    cat    cat    dog    cat    dog                 dog\n",
       "1    dog    dog    cat    cat    dog                 dog\n",
       "2    dog    cat    cat    cat    dog                 dog\n",
       "3    dog    dog    dog    cat    dog                 dog\n",
       "4    cat    cat    cat    dog    dog                 dog"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOW WE CREATE a BASELINE MODEL where DOG is Positive case (most common) and CAT is Negative case\n",
    "### Set the baseline_prediction to be dog...it is the most common class\n",
    "\n",
    "df['baseline_prediction'] = 'dog'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f397b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>baseline_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  actual baseline_prediction\n",
       "0    cat                 dog\n",
       "1    dog                 dog\n",
       "2    dog                 dog\n",
       "3    dog                 dog\n",
       "4    cat                 dog"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_base = df.drop(columns=['model1','model2','model3','model4'])\n",
    "df_base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8d3b164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>actual</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseline_prediction</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>1746</td>\n",
       "      <td>3254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "actual                cat   dog\n",
       "baseline_prediction            \n",
       "dog                  1746  3254"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(df.baseline_prediction,df.actual)  #3254 dogs and 1746 cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8fc1979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 ACC: 0.8074\n",
      "Baseline ACC: 0.6508\n"
     ]
    }
   ],
   "source": [
    "# 4a How does each model ACCURACY compare to BASELINE ACCURACY?\n",
    "model1_acc = (df1.model1 == df1.actual).mean()\n",
    "baseline_acc = (df_base.baseline_prediction == df_base.actual).mean()\n",
    "print(f'Model 1 ACC: {model1_acc}')\n",
    "print(f'Baseline ACC: {baseline_acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "01eb264d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 ACC: 0.6304\n",
      "Baseline ACC: 0.6508\n"
     ]
    }
   ],
   "source": [
    "model2_acc = (df2.model2 == df2.actual).mean()\n",
    "baseline_acc = (df_base.baseline_prediction == df_base.actual).mean()\n",
    "print(f'Model 2 ACC: {model2_acc}')\n",
    "print(f'Baseline ACC: {baseline_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "196b180b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3 ACC: 0.5096\n",
      "Baseline ACC: 0.6508\n"
     ]
    }
   ],
   "source": [
    "model3_acc = (df3.model3 == df3.actual).mean()\n",
    "baseline_acc = (df_base.baseline_prediction == df_base.actual).mean()\n",
    "print(f'Model 3 ACC: {model3_acc}')\n",
    "print(f'Baseline ACC: {baseline_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ba718de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 4 ACC: 0.7426\n",
      "Baseline ACC: 0.6508\n"
     ]
    }
   ],
   "source": [
    "model4_acc = (df4.model4 == df4.actual).mean()\n",
    "baseline_acc = (df_base.baseline_prediction == df_base.actual).mean()\n",
    "print(f'Model 4 ACC: {model4_acc}')\n",
    "print(f'Baseline ACC: {baseline_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f2928a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACCURACY of MODEL 1 is the highest at 0.807...model 1 (.807) and model 4 (.743) are BETTER than BASELINE\n",
    "# Suppose DOG team...recommend model with BEST RECALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "476a9224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>model1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  actual model1\n",
       "0    cat    cat\n",
       "1    dog    dog\n",
       "2    dog    cat\n",
       "3    dog    dog\n",
       "4    cat    cat"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "98756899",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>model3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    actual  model3\n",
       "13  Defect  Defect\n",
       "30  Defect  Defect\n",
       "65  Defect  Defect\n",
       "70  Defect  Defect\n",
       "74  Defect  Defect"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f4521af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.803318992009834"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = df1[df1.actual == 'dog']\n",
    "subset.shape\n",
    "\n",
    "model1_recall = (subset.model1 == subset.actual).mean()\n",
    "model1_recall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bbb1241f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49078057775046097"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = df2[df2.actual == 'dog']\n",
    "subset.shape\n",
    "\n",
    "model2_recall = (subset.model2 == subset.actual).mean()\n",
    "model2_recall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "20119653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5086047940995697"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = df3[df3.actual == 'dog']\n",
    "subset.shape\n",
    "\n",
    "model3_recall = (subset.model3 == subset.actual).mean()\n",
    "model3_recall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2a0ced78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9557467732022127"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = df4[df4.actual == 'dog']\n",
    "subset.shape\n",
    "\n",
    "model4_recall = (subset.model4 == subset.actual).mean()\n",
    "model4_recall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5893c9f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dog    4253\n",
       "cat     747\n",
       "Name: model4, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.model4.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7ffe0446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL 4 has BEST RECALL at 0.956!!!!\n",
    "# Now what about best PRECISION for cats...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ce314279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1 precision: 89.00%\n"
     ]
    }
   ],
   "source": [
    "# MODEL 1 PRECISION\n",
    "\n",
    "subset = df1[df1.model1 == 'dog']\n",
    "model1_precision = (subset.model1 == subset.actual).mean()\n",
    "\n",
    "print(f'model 1 precision: {model1_precision:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9b6c9037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 2 precision: 89.32%\n"
     ]
    }
   ],
   "source": [
    "# MODEL 2 PRECISION\n",
    "\n",
    "subset = df2[df2.model2 == 'dog']\n",
    "model2_precision = (subset.model2 == subset.actual).mean()\n",
    "\n",
    "print(f'model 2 precision: {model2_precision:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9d8f65e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 3 precision: 65.99%\n"
     ]
    }
   ],
   "source": [
    "# MODEL 3 PRECISION\n",
    "\n",
    "subset = df3[df3.model3 == 'dog']\n",
    "model3_precision = (subset.model3 == subset.actual).mean()\n",
    "\n",
    "print(f'model 3 precision: {model3_precision:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "298a21c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 4 precision: 73.12%\n"
     ]
    }
   ],
   "source": [
    "# MODEL 4 PRECISION\n",
    "\n",
    "subset = df4[df4.model4 == 'dog']\n",
    "model4_precision = (subset.model4 == subset.actual).mean()\n",
    "\n",
    "print(f'model 4 precision: {model4_precision:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bb93e561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEST PRECISION ... Model 2 at 0.893"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0e3fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b92f31b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 Apply the following functions to previous data\n",
    "\n",
    "# ACCURACY..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9c73854f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8074"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(df1.actual,df1.model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2e724080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6304"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(df2.actual,df2.model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "268c807f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5096"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(df3.actual,df3.model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c96bf30f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7426"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(df4.actual,df4.model4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3e84c626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRECISION..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5a4427d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8900238338440586"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.precision_score(df1.actual,df1.model1,pos_label='dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "74d9980f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8931767337807607"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.precision_score(df2.actual,df2.model2,pos_label='dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f2d3bf3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6598883572567783"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.precision_score(df3.actual,df3.model3,pos_label='dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f2f117f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7312485304490948"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.precision_score(df4.actual,df4.model4,pos_label='dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "714c50bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RECALL..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dcfb8429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.803318992009834"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.recall_score(df1.actual,df1.model1,pos_label='dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f7556994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49078057775046097"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.recall_score(df2.actual,df2.model2,pos_label='dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "74a41351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5086047940995697"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.recall_score(df3.actual,df3.model3,pos_label='dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b6544899",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9557467732022127"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.recall_score(df4.actual,df4.model4,pos_label='dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "90820fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OVERALL CLASSIFICATION REPORT..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "448d3214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         cat       0.69      0.82      0.75      1746\n",
      "         dog       0.89      0.80      0.84      3254\n",
      "\n",
      "    accuracy                           0.81      5000\n",
      "   macro avg       0.79      0.81      0.80      5000\n",
      "weighted avg       0.82      0.81      0.81      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.classification_report(df1.actual,df1.model1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0ee51a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         cat       0.48      0.89      0.63      1746\n",
      "         dog       0.89      0.49      0.63      3254\n",
      "\n",
      "    accuracy                           0.63      5000\n",
      "   macro avg       0.69      0.69      0.63      5000\n",
      "weighted avg       0.75      0.63      0.63      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.classification_report(df2.actual,df2.model2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "583e6139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         cat       0.36      0.51      0.42      1746\n",
      "         dog       0.66      0.51      0.57      3254\n",
      "\n",
      "    accuracy                           0.51      5000\n",
      "   macro avg       0.51      0.51      0.50      5000\n",
      "weighted avg       0.55      0.51      0.52      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.classification_report(df3.actual,df3.model3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "afd7e08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         cat       0.81      0.35      0.48      1746\n",
      "         dog       0.73      0.96      0.83      3254\n",
      "\n",
      "    accuracy                           0.74      5000\n",
      "   macro avg       0.77      0.65      0.66      5000\n",
      "weighted avg       0.76      0.74      0.71      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.classification_report(df4.actual,df4.model4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30519b66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647ef9ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee39a9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
